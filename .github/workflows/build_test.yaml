name: Build and test torchcomms

on:
  push:
    branches:
      - main
  pull_request:

jobs:
  build_test:
    strategy:
      fail-fast: false
      matrix:
        include:
          - runs-on: "linux.g5.12xlarge.nvidia.gpu"
            gpu-arch-type: "cuda"
            gpu-arch-version: "12.8"
            torch-version: "stable"
            cmake-version: "3.22.1"
          - runs-on: "linux.g5.12xlarge.nvidia.gpu"
            gpu-arch-type: "cuda"
            gpu-arch-version: "12.8"
            torch-version: "nightly"
            cmake-version: "latest"

    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    with:
      timeout: 120
      runner: ${{ matrix.runs-on }}
      gpu-arch-type: ${{ matrix.gpu-arch-type }}
      gpu-arch-version: ${{ matrix.gpu-arch-version }}
      script: |
        set -ex
        # use faster libmamba solver
        conda config --set solver libmamba

        conda create -n venv python=3.12 ninja -y
        conda activate venv
        python -m pip install --upgrade pip

        # Optionally install torch nightly, pulls latest CUDA from pip otherwise
        if [ "${{ matrix.torch-version }}" = "nightly" ]; then
          pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
        fi

        if [ "${{ matrix.cmake-version }}" = "latest" ]; then
          conda install -y cmake
        else # default to latest
          conda install -y cmake==${{ matrix.cmake-version }}
        fi

        pip install -r requirements.txt

        # Build C++
        ./build_ncclx.sh

        # Build pybindings
        pip install --no-build-isolation -v '.[dev]'
        python -c "import torchcomms"

        # Run tests
        comms/torchcomms/scripts/run_tests_integration_py.sh
        pytest -v comms/torchcomms/tests/unit/py
